import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
from datetime import datetime

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
st.set_page_config(page_title="ĞšĞ»Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ", layout="wide")
st.image("orig.png", width=120)
st.title("Ğ”Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¸Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼")

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼
uploaded_file = st.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ JSON Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸", type="json")

if uploaded_file is not None:
    try:
        reviews_data = json.load(uploaded_file)

        # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· API
        def fetch_predictions(data):
            url = "http://localhost:8000/predict"
            response = requests.post(url, json={"data": data})
            if response.status_code == 200:
                return response.json()
            else:
                st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº API: {response.text}")
                return None

        predictions_data = fetch_predictions(reviews_data)

        if predictions_data:
            # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹
            flat_data = []
            for pred in predictions_data:
                for topic, sentiment in zip(pred["topics"], pred["sentiments"]):
                    flat_data.append({"id": pred["id"], "topic": topic, "sentiment": sentiment})
            flat_df = pd.DataFrame(flat_data)

            # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸
            merged_df = reviews_df.merge(flat_df, on="id", how="left")

            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğ°Ğ¼
            date_range = st.sidebar.slider(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»:",
                min_value=merged_df["date"].min().to_pydatetime(),
                max_value=merged_df["date"].max().to_pydatetime(),
                value=(merged_df["date"].min().to_pydatetime(), merged_df["date"].max().to_pydatetime())
            )
            filtered_df = merged_df[(merged_df["date"] >= pd.to_datetime(date_range[0])) &
                                    (merged_df["date"] <= pd.to_datetime(date_range[1]))]

            # ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ÑĞºĞ° Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²/ÑƒÑĞ»ÑƒĞ³
            st.subheader("ğŸ“‹ Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²/ÑƒÑĞ»ÑƒĞ³")
            topics = filtered_df["topic"].unique()
            st.write(topics)

            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑĞ¼
            st.subheader("âš–ï¸ Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğ°Ğ¼")
            sentiment_counts = filtered_df.groupby(["topic", "sentiment"]).size().reset_index(name="count")
            fig = px.bar(sentiment_counts, x="topic", y="count", color="sentiment", barmode="stack")
            st.plotly_chart(fig, use_container_width=True)

            # Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
            st.subheader("ğŸ“ˆ Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸")
            time_series = filtered_df.groupby([filtered_df["date"].dt.date, "sentiment"]).size().reset_index(name="count")
            fig2 = px.line(time_series, x="date", y="count", color="sentiment", markers=True)
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚ API.")
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞµ Ñ„Ğ°Ğ¹Ğ»Ğ°: {e}")
else:
    st.info("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ°Ğ¼Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON.")
